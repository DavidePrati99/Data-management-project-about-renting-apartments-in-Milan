{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ccdbaa",
   "metadata": {},
   "source": [
    "<h1> Progetto DataManagement </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a477efd2",
   "metadata": {},
   "source": [
    "<h2>1) Creazione del database e tabelle </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "034188f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo la libreria per poter effettuare la connessione\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4462b3",
   "metadata": {},
   "source": [
    "<b> Creazione e connessione con il database </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16bd6e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('DataManagement.db')\n",
    "conn.execute('PRAGMA foreign_keys = ON')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82499141",
   "metadata": {},
   "source": [
    "<b> Creazione tabella comuni </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a05cd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2646f1ec0a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS comuni (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        nome TEXT,\n",
    "        comune_appartenenza TEXT,\n",
    "        comuneId INTEGER,\n",
    "        `vendita_minima(€/mese)` DECIMAL(10,2),\n",
    "        `vendita_media(€/mese)` DECIMAL(10,2),\n",
    "        `vendita_massima(€/mese)` DECIMAL(10,2),\n",
    "        `affitto_minimo(€/mese)` DECIMAL(10,2),\n",
    "        `affitto_medio(€/mese)` DECIMAL(10,2),\n",
    "        `affitto_massimo(€/mese)` DECIMAL(10,2),\n",
    "        popolazione number(10,2),      \n",
    "        `densita_popolazione(ab./km²)` number(10,2),\n",
    "        `superficie(km²)` number(10,2),\n",
    "        famiglie number(10,2),\n",
    "        `maschi(%)` number(10,2),\n",
    "        `femmine(%)` number(10,2),\n",
    "        `stranieri(%)` number(10,2),\n",
    "        `eta_media(anni)` number(10,2),\n",
    "        FOREIGN KEY (comuneId) REFERENCES comuni(id) ON DELETE CASCADE\n",
    "    )\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a5c78f",
   "metadata": {},
   "source": [
    "<b> Creazione tabella affitti </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9b56fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2646f1ec0a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS affitti (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        nome TEXT,\n",
    "        comuneId INTEGER,\n",
    "        contratto TEXT,\n",
    "        tipologia TEXT,\n",
    "        `superficie(m²)` DECIMAL(10,2),\n",
    "        locali INTEGER,\n",
    "        locali_descrizione TEXT,\n",
    "        piani TEXT,\n",
    "        indirizzo TEXT,\n",
    "        latitudine TEXT,\n",
    "        longitudine TEXT,\n",
    "        stazioneId INTEGER,\n",
    "        `stazione_distanza(metri)` INTEGER,\n",
    "        `stazione_distanza(minuti)` INTEGER,\n",
    "        `prezzo(€/mese)` DECIMAL(10,2),\n",
    "        `prezzo_minimo(€/mese)` DECIMAL(10,2),\n",
    "        `prezzo_massimo(€/mese)` DECIMAL(10,2),\n",
    "        box_auto INTEGER,\n",
    "        `giardino(m²)` INTEGER,\n",
    "        balcone INTEGER,\n",
    "        ascensore INTEGER,\n",
    "        fumatori INTEGER,\n",
    "        animali INTEGER,\n",
    "        url_annuncio TEXT,    \n",
    "        FOREIGN KEY (comuneId) REFERENCES comuni(id) ON DELETE CASCADE\n",
    "        FOREIGN KEY (stazioneId) REFERENCES mezzi_pubblici(id) ON DELETE CASCADE\n",
    "    )\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4af446",
   "metadata": {},
   "source": [
    "<b> Creazione tabella luoghi_interesse </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85972323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2646f1ec0a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS luoghi_interesse (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        nome TEXT,\n",
    "        descrizione TEXT,\n",
    "        latitudine TEXT,\n",
    "        longitudine TEXT,\n",
    "        tempo_arrivo TEXT,\n",
    "        week_day TEXT\n",
    "    )\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83ba9ff",
   "metadata": {},
   "source": [
    "<b> Creazione tabella mezzi_pubblici </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02e401a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2646f1ec0a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS mezzi_pubblici (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        nome TEXT,\n",
    "        areaSTIBM TEXT,\n",
    "        latitudine TEXT,\n",
    "        longitudine TEXT,\n",
    "        tipo_mezzo TEXT\n",
    "    )\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf5e698",
   "metadata": {},
   "source": [
    "<b> Creazione tabella mezzi_luogo </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa3a6162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1f960d25490>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS mezzi_luogo (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        id_mezzi_pubblici INTEGER,\n",
    "        id_luogo_interesse INTEGER,\n",
    "        `distanza(minuti)` INTEGER,\n",
    "        `distanza(km)` INTEGER,\n",
    "        FOREIGN KEY (id_mezzi_pubblici) REFERENCES mezzi_pubblici(id) ON DELETE CASCADE\n",
    "        FOREIGN KEY (id_luogo_interesse) REFERENCES luoghi_interesse(id) ON DELETE CASCADE\n",
    "    )\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "919780c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effettuo una commit delle tabelle create\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c056f",
   "metadata": {},
   "source": [
    "<b> Cancello le tabelle create </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "427bbd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2646f1ce650>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"drop table comuni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "078d961e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2646f1ce650>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"drop table affitti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6323e26d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such table: luoghi_interesse",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8784497b8805>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"drop table luoghi_interesse\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m: no such table: luoghi_interesse"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"drop table luoghi_interesse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91418d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2646f1ce650>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"drop table mezzi_pubblici\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4d17d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1f960d25490>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"drop table mezzi_luogo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db85d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d61101",
   "metadata": {},
   "source": [
    "<h2> 2) Utilizzo le API per prelevare i dati sui mezzi pubblici</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06b31fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "from numpy import isnan\n",
    "from numpy import NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5df3145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data request to Overpass API using Overpass QL \n",
    "url = \"https://maps.mail.ru/osm/tools/overpass/api/interpreter\"\n",
    "query = \"\"\"\n",
    "        [out:json];\n",
    "        area[name=\"Milano\"];\n",
    "        nwr[railway=station][station=subway](area);\n",
    "        out center;\n",
    "        \"\"\"\n",
    "response = requests.get(url, params={'data': query})\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36a2ad92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-aaef25273577>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metro_df['tags.description'][i] = metro_df['tags.description'][i].replace('Area STIBM: ', '')\n"
     ]
    }
   ],
   "source": [
    "# conversion to tabular\n",
    "metro_df = json_normalize(data['elements'])\n",
    "\n",
    "# feature selection\n",
    "feature = ['tags.name','tags.description','lon','lat']\n",
    "metro_df = metro_df[feature]\n",
    "\n",
    "# strip 'Area STIBM:' from tags.description\n",
    "for i in range(0, metro_df.shape[0]):\n",
    "    if metro_df['tags.description'][i] is not NaN:\n",
    "        metro_df['tags.description'][i] = metro_df['tags.description'][i].replace('Area STIBM: ', '')\n",
    "\n",
    "# renaming columns\n",
    "metro_df.rename(columns={\"tags.name\":\"name\",\"tags.description\":\"Area STIBM\"}, inplace=True)\n",
    "\n",
    "# drop duplicate (stations where metro lines meet are duplicated) \n",
    "metro_df.drop_duplicates(subset=['name'], ignore_index=True, inplace=True)\n",
    "\n",
    "# drop station with unknown location\n",
    "metro_df.drop(metro_df[isnan(metro_df['lon']) & isnan(metro_df['lat'])].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d29bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://maps.mail.ru/osm/tools/overpass/api/interpreter\"\n",
    "query = \"\"\"\n",
    "        [out:json];\n",
    "        area[name=\"Milano\"];\n",
    "        nwr[railway=station][station!=subway](area);\n",
    "        out center;\n",
    "        \"\"\"\n",
    "response = requests.get(url, params={'data': query})\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b096aeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-9ffab8ca2c1a>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['tags.description'][i] = train_df['tags.description'][i].replace('Area STIBM: ', '')\n"
     ]
    }
   ],
   "source": [
    "# conversion to tabular\n",
    "train_df = json_normalize(data['elements'])\n",
    "\n",
    "# feature selection\n",
    "feature = ['tags.name','tags.description','lon','lat']\n",
    "train_df = train_df[feature]\n",
    "\n",
    "# strip 'Area STIBM:' from tags.description\n",
    "for i in range(0, train_df.shape[0]):\n",
    "    if train_df['tags.description'][i] is not NaN:\n",
    "        train_df['tags.description'][i] = train_df['tags.description'][i].replace('Area STIBM: ', '')\n",
    "\n",
    "# renaming columns\n",
    "train_df.rename(columns={\"tags.name\":\"name\",\"tags.description\":\"Area STIBM\"}, inplace=True)\n",
    "\n",
    "# drop duplicate (stations where metro lines meet are duplicated) \n",
    "train_df.drop_duplicates(subset=['name'], ignore_index=True, inplace=True)\n",
    "\n",
    "# drop station with unknown location\n",
    "train_df.drop(train_df[isnan(train_df['lon']) & isnan(train_df['lat'])].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3946f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join train and metro dataframes into one\n",
    "train_df['station_type']='treno'\n",
    "metro_df['station_type']='metro'\n",
    "public_transport_df = pd.concat([train_df,metro_df], ignore_index=True)\n",
    "public_transport_df.index += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75e21e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Area STIBM</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>station_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Milano Cadorna</td>\n",
       "      <td>Mi1</td>\n",
       "      <td>9.175523</td>\n",
       "      <td>45.468405</td>\n",
       "      <td>treno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Milano Porta Garibaldi (superficie)</td>\n",
       "      <td>Mi1</td>\n",
       "      <td>9.187309</td>\n",
       "      <td>45.484530</td>\n",
       "      <td>treno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Milano San Cristoforo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.130128</td>\n",
       "      <td>45.442302</td>\n",
       "      <td>treno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milano Greco Pirelli</td>\n",
       "      <td>Mi1</td>\n",
       "      <td>9.214188</td>\n",
       "      <td>45.512889</td>\n",
       "      <td>treno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rho</td>\n",
       "      <td>Mi4</td>\n",
       "      <td>9.043565</td>\n",
       "      <td>45.524102</td>\n",
       "      <td>treno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Isola</td>\n",
       "      <td>Mi1</td>\n",
       "      <td>9.191294</td>\n",
       "      <td>45.487612</td>\n",
       "      <td>metro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Dateo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.218447</td>\n",
       "      <td>45.468001</td>\n",
       "      <td>metro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Argonne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.231908</td>\n",
       "      <td>45.468083</td>\n",
       "      <td>metro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Susa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.224874</td>\n",
       "      <td>45.468067</td>\n",
       "      <td>metro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Tricolore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.207774</td>\n",
       "      <td>45.467906</td>\n",
       "      <td>metro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name Area STIBM       lon        lat  \\\n",
       "1                         Milano Cadorna        Mi1  9.175523  45.468405   \n",
       "2    Milano Porta Garibaldi (superficie)        Mi1  9.187309  45.484530   \n",
       "3                  Milano San Cristoforo        NaN  9.130128  45.442302   \n",
       "4                   Milano Greco Pirelli        Mi1  9.214188  45.512889   \n",
       "5                                    Rho        Mi4  9.043565  45.524102   \n",
       "..                                   ...        ...       ...        ...   \n",
       "173                                Isola        Mi1  9.191294  45.487612   \n",
       "174                                Dateo        NaN  9.218447  45.468001   \n",
       "175                              Argonne        NaN  9.231908  45.468083   \n",
       "176                                 Susa        NaN  9.224874  45.468067   \n",
       "177                            Tricolore        NaN  9.207774  45.467906   \n",
       "\n",
       "    station_type  \n",
       "1          treno  \n",
       "2          treno  \n",
       "3          treno  \n",
       "4          treno  \n",
       "5          treno  \n",
       "..           ...  \n",
       "173        metro  \n",
       "174        metro  \n",
       "175        metro  \n",
       "176        metro  \n",
       "177        metro  \n",
       "\n",
       "[177 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_transport_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a76ffcf",
   "metadata": {},
   "source": [
    "<b>Creo un file csv del mio dataFrame </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a62a3501",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_transport_df.to_csv('mezzi_pubblici.csv', index=True, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7daa2f",
   "metadata": {},
   "source": [
    "<h2> 3) Creare un dataframe coi luoghi d'interesse da un csv creato in precedenza </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81af91d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "luoghi_interesse = pd.read_csv('luoghi_interesse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90c029a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "luoghi_interesse.index += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36787ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome</th>\n",
       "      <th>descrizione</th>\n",
       "      <th>latitudine</th>\n",
       "      <th>longitudine</th>\n",
       "      <th>tempo_arrivo</th>\n",
       "      <th>week_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Università degli Studi di Milano Bicocca Piazz...</td>\n",
       "      <td>Bicocca</td>\n",
       "      <td>45.518316</td>\n",
       "      <td>9.213788</td>\n",
       "      <td>8:30</td>\n",
       "      <td>VERO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Politecnico di Milano Piazza Leonardo da Vinci 32</td>\n",
       "      <td>Polimi Piola</td>\n",
       "      <td>45.478188</td>\n",
       "      <td>9.227235</td>\n",
       "      <td>8:30</td>\n",
       "      <td>VERO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politecnico di Milano - Campus Bovisa La Masa ...</td>\n",
       "      <td>Polimi Bovisa</td>\n",
       "      <td>45.502873</td>\n",
       "      <td>9.156420</td>\n",
       "      <td>8:30</td>\n",
       "      <td>VERO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Università degli Studi di Milano Via Festa del...</td>\n",
       "      <td>Statale sede principale</td>\n",
       "      <td>45.460395</td>\n",
       "      <td>9.194151</td>\n",
       "      <td>8:30</td>\n",
       "      <td>VERO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arco della Pace Piazza Sempione</td>\n",
       "      <td>Arco della pace</td>\n",
       "      <td>45.475715</td>\n",
       "      <td>9.172451</td>\n",
       "      <td>20:00</td>\n",
       "      <td>FALSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Piazza del Duomo- Milano</td>\n",
       "      <td>Piazza Duomo</td>\n",
       "      <td>45.464230</td>\n",
       "      <td>9.189630</td>\n",
       "      <td>15:00</td>\n",
       "      <td>FALSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stadio San Siro Piazzale Angelo Moratti</td>\n",
       "      <td>Stadio San Siro</td>\n",
       "      <td>45.478061</td>\n",
       "      <td>9.123959</td>\n",
       "      <td>20:00</td>\n",
       "      <td>FALSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pinacoteca di Brera Via Brera 28</td>\n",
       "      <td>Pinacoteca di Brera</td>\n",
       "      <td>45.471954</td>\n",
       "      <td>9.187814</td>\n",
       "      <td>15:00</td>\n",
       "      <td>FALSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Darsena del Naviglio</td>\n",
       "      <td>Navigli</td>\n",
       "      <td>45.452553</td>\n",
       "      <td>9.178126</td>\n",
       "      <td>20:00</td>\n",
       "      <td>FALSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alcatraz Via Valtellina</td>\n",
       "      <td>Alcatraz</td>\n",
       "      <td>45.494696</td>\n",
       "      <td>9.182647</td>\n",
       "      <td>20:00</td>\n",
       "      <td>FALSO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 nome  \\\n",
       "1   Università degli Studi di Milano Bicocca Piazz...   \n",
       "2   Politecnico di Milano Piazza Leonardo da Vinci 32   \n",
       "3   Politecnico di Milano - Campus Bovisa La Masa ...   \n",
       "4   Università degli Studi di Milano Via Festa del...   \n",
       "5                     Arco della Pace Piazza Sempione   \n",
       "6                            Piazza del Duomo- Milano   \n",
       "7             Stadio San Siro Piazzale Angelo Moratti   \n",
       "8                    Pinacoteca di Brera Via Brera 28   \n",
       "9                                Darsena del Naviglio   \n",
       "10                            Alcatraz Via Valtellina   \n",
       "\n",
       "                descrizione  latitudine  longitudine tempo_arrivo week_day  \n",
       "1                   Bicocca   45.518316     9.213788         8:30     VERO  \n",
       "2              Polimi Piola   45.478188     9.227235         8:30     VERO  \n",
       "3             Polimi Bovisa   45.502873     9.156420         8:30     VERO  \n",
       "4   Statale sede principale   45.460395     9.194151         8:30     VERO  \n",
       "5           Arco della pace   45.475715     9.172451        20:00    FALSO  \n",
       "6              Piazza Duomo   45.464230     9.189630        15:00    FALSO  \n",
       "7           Stadio San Siro   45.478061     9.123959        20:00    FALSO  \n",
       "8       Pinacoteca di Brera   45.471954     9.187814        15:00    FALSO  \n",
       "9                   Navigli   45.452553     9.178126        20:00    FALSO  \n",
       "10                 Alcatraz   45.494696     9.182647        20:00    FALSO  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luoghi_interesse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528e64a5",
   "metadata": {},
   "source": [
    "<h2> 4) Popolo le tabelle con i dati dei csv </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a75ff7",
   "metadata": {},
   "source": [
    "<b>Inserisco i dati dei mezzi pubblici in tabella </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c096598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2c00291",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mezzi_pubblici.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        id_mezzo = int(row[0])\n",
    "        nome = str(row[1]).replace(\"'\", \" \").replace(\"Ã\", \"à\").replace('â€™', \" \").replace('Âº', '').replace('à²','ò')\n",
    "        area = str(row[2])\n",
    "        latitudine = str(row[3])\n",
    "        longitudine = str(row[4])\n",
    "        tipo = str(row[5]).replace(';', '')\n",
    "        # Costruisci la query SQL per l'inserimento\n",
    "        insert_query = f\"INSERT INTO mezzi_pubblici (id, nome, areaSTIBM, latitudine, longitudine, tipo_mezzo ) VALUES ('{id_mezzo}','{nome}','{area}','{latitudine}','{longitudine}','{tipo}')\"\n",
    "        # Esegui la query\n",
    "        cursor.execute(insert_query)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d0bec",
   "metadata": {},
   "source": [
    "<b>Inserisco i dati dei luoghi di interesse in tabella </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0796a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "with open('luoghi_interesse.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        nome = str(row[0]).replace(\"'\", \" \").replace(\"Ã\", \"à\")\n",
    "        descrizione = str(row[1])\n",
    "        latitudine = str(row[2])\n",
    "        longitudine = str(row[3])\n",
    "        tempo = str(row[4])\n",
    "        week_day = str(row[5])\n",
    "        # Costruisci la query SQL per l'inserimento\n",
    "        if (cont > 0):\n",
    "            insert_query = f\"INSERT INTO luoghi_interesse (nome, descrizione, latitudine, longitudine, tempo_arrivo, week_day) VALUES ('{nome}','{descrizione}','{latitudine}','{longitudine}','{tempo}','{week_day}')\"\n",
    "            cursor.execute(insert_query)\n",
    "            conn.commit()\n",
    "        cont = cont+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d8ae7b",
   "metadata": {},
   "source": [
    "<h2> 4) Utilizzo Selenium per trovare distanza e tempo tra luoghi e stazione</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02f8bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import required modules #####\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "072265b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### define functions #####\n",
    "\n",
    "## set_up ## \n",
    "# opens and sets up the google maps page\n",
    "# arrive_time: set the arrive time; format 'hh:mm'\n",
    "# week_day: set the arrive day; accepted value = True (day is set to monday), False (day is set to saturday)\n",
    "\n",
    "def set_up(arrive_time,week_day):\n",
    "\n",
    "    # assign url in the webdriver object\n",
    "    global driver \n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(\"https://www.google.it/maps/dir/@45.5038144,9.4419926,15z?entry=ttu\")\n",
    "    sleep(2)\n",
    "\n",
    "    # Accept cookie policy\n",
    "    Submit = driver.find_elements(By.TAG_NAME, \"button\")\n",
    "    Submit[1].click()\n",
    "    sleep(2)\n",
    "\n",
    "    # initialize the page with an arbitrary search\n",
    "    searchplace(\"metro precotto\",\"Piazza della Scienza, 20126 Milano MI\")\n",
    "    sleep(5)\n",
    "\n",
    "    # select \"arrive by\" mode\n",
    "    driver.find_element(By.XPATH,'//*[@id=\":3\"]').click()\n",
    "    driver.find_element(By.XPATH,'//*[@id=\":2\"]').click()\n",
    "    sleep(1)\n",
    "\n",
    "    # select arrive time\n",
    "    path ='//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/span[1]/input'\n",
    "    driver.find_element(By.XPATH,path).clear()\n",
    "    driver.find_element(By.XPATH,path).send_keys(arrive_time)\n",
    "    sleep(1)\n",
    "\n",
    "    # select arrive day\n",
    "    path_testo ='//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/span[2]/span[1]'\n",
    "    path_bottone = '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/span[2]/span[2]/button[2]'\n",
    "    giorno = driver.find_element(By.XPATH,path_testo).text\n",
    "\n",
    "    if week_day:\n",
    "        target = 'lun'\n",
    "    else:\n",
    "        target = 'sab'\n",
    "            \n",
    "    while (not target in giorno):\n",
    "        driver.find_element(By.XPATH,path_bottone).click()\n",
    "        giorno = driver.find_element(By.XPATH,path_testo).text\n",
    "        sleep(1)\n",
    "\n",
    "        \n",
    "## searchplace ## \n",
    "# inputs starting point (A) and destination (B)\n",
    "\n",
    "def searchplace(A,B):\n",
    "    Place = driver.find_elements(By.CLASS_NAME,\"tactile-searchbox-input\")\n",
    "    Place[0].clear()\n",
    "    Place[0].send_keys(A)\n",
    "    Place[1].clear()\n",
    "    Place[1].send_keys(B)\n",
    "    Place[1].send_keys(Keys.RETURN)\n",
    "    \n",
    "    \n",
    "## extract_time ##\n",
    "# extracts the time needed to get from A to B by public transport\n",
    "\n",
    "def extract_time():\n",
    "    # read time from the web page\n",
    "    path_tempo = '//*[@id=\"omnibox-directions\"]/div/div[2]/div/div/div/div[3]/button/div[1]'\n",
    "    tempo = driver.find_element(By.XPATH,path_tempo).text\n",
    "    # convert time format in number of minutes \n",
    "    if tempo!='':\n",
    "        numbers = [int(s) for s in tempo.split() if s.isdigit()]\n",
    "        if len(numbers)==2:\n",
    "            time = numbers[0]*60 + numbers[1]\n",
    "        else:\n",
    "            time = numbers[0] \n",
    "    else:\n",
    "        time = 0\n",
    "    \n",
    "    return int(time) \n",
    "\n",
    "\n",
    "## time_table ##\n",
    "# compute the time needed to get from each metro and train station to a given point of interest\n",
    "# point of interest: a string that google maps interprets as the desired place\n",
    "# delay: sets the timing of the loop, adjust for internet speed\n",
    "# arrive_time: set the arrive time; format 'hh:mm'\n",
    "# week_day: set the arrive day; accepted value = True(day is set to monday), False(day is set to saturday)\n",
    "\n",
    "def time_table(point_of_intrest, arrive_time, week_day ,delay=5):\n",
    "    set_up(arrive_time,week_day)\n",
    "    time_list = []\n",
    "    station_id = []\n",
    "    \n",
    "    # loops over stations and retrives the needed time storing it along\n",
    "    # with the station index in time_list an station_id respectively\n",
    "    for index,row in tqdm(public_transport_df.iterrows(),total=public_transport_df.shape[0], desc='Progress'):\n",
    "        station = row['name'] + ' ' + row['station_type']\n",
    "        searchplace(station,point_of_intrest)\n",
    "        sleep(delay)\n",
    "        tempo = extract_time()\n",
    "        time_list.append(tempo)\n",
    "        station_id.append(index)\n",
    "        \n",
    "    # creates a dataframe containing station_id and time_list   \n",
    "    df = pd.DataFrame(data={'station_id': station_id, 'time': time_list})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12696a43",
   "metadata": {},
   "source": [
    "<b> Faccio partire i cicli iterativi con selenium per recuperare la relazione </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd9695ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance\n",
    "def air_distance(lon1, lat1, lon2, lat2):\n",
    "    coords_1 = (lon1,lat1)\n",
    "    coords_2 = (lon2,lat2)\n",
    "    return geopy.distance.geodesic(coords_1, coords_2).km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1bca6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea5133a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████████████████████████████████████████████████████████████████| 177/177 [10:27<00:00,  3.54s/it]\n",
      "Progress: 100%|██████████████████████████████████████████████████████████████████████| 177/177 [10:29<00:00,  3.56s/it]\n",
      "Progress: 100%|██████████████████████████████████████████████████████████████████████| 177/177 [10:14<00:00,  3.47s/it]\n",
      "Progress: 100%|██████████████████████████████████████████████████████████████████████| 177/177 [10:14<00:00,  3.47s/it]\n",
      "Progress: 100%|██████████████████████████████████████████████████████████████████████| 177/177 [10:26<00:00,  3.54s/it]\n",
      "Progress: 100%|██████████████████████████████████████████████████████████████████████| 177/177 [10:17<00:00,  3.49s/it]\n",
      "Progress: 100%|██████████████████████████████████████████████████████████████████████| 177/177 [10:18<00:00,  3.49s/it]\n",
      "Progress: 100%|██████████████████████████████████████████████████████████████████████| 177/177 [10:18<00:00,  3.49s/it]\n",
      "Progress: 100%|██████████████████████████████████████████████████████████████████████| 177/177 [10:17<00:00,  3.49s/it]\n",
      "Progress: 100%|██████████████████████████████████████████████████████████████████████| 177/177 [10:16<00:00,  3.48s/it]\n"
     ]
    }
   ],
   "source": [
    "for index, row in luoghi_interesse.iterrows():\n",
    "    id_luogo = index\n",
    "    df = time_table(row['nome'], row['tempo_arrivo'], row['week_day'], delay=3)\n",
    "    for index1, row1 in df.iterrows():\n",
    "        id_station = row1['station_id']\n",
    "        tempo = row1['time']\n",
    "        distanza = round(air_distance(row['longitudine'], row['latitudine'], public_transport_df.iloc[index1]['lon'], public_transport_df.iloc[index1]['lat']),2) \n",
    "        tempo = int(tempo) if (tempo!=0) else int(distanza*12)\n",
    "        cursor.execute(f\"INSERT INTO mezzi_luogo(id_mezzi_pubblici, id_luogo_interesse, `distanza(minuti)`, `distanza(km)`) VALUES('{id_station}','{id_luogo}','{tempo}','{distanza}')\")\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec0d82",
   "metadata": {},
   "source": [
    "<h2> 5) Scrapyng dati e storage su database </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb5307a",
   "metadata": {},
   "source": [
    "<b>Importo le librerie necessarie per lo scraping</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdf60a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "import logging\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a0d9be",
   "metadata": {},
   "source": [
    "<b>Inserisco l'indirizzo url per effettuare lo scraping</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e6e2cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.immobiliare.it/mercato-immobiliare/lombardia/milano-provincia/\" \n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac63cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa7a1ed",
   "metadata": {},
   "source": [
    "<b>Recupero il div con l'elenco dei link di tutte le province</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e30f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "div_link_comuni = soup.find_all('a', {\"class\": \"nd-table__url\"}, href=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1646e088",
   "metadata": {},
   "source": [
    "<b>Creo una lista coi singoli link delle pagine da dove fare scraping</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "661555bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_link_comuni = []\n",
    "for link in div_link_comuni:\n",
    "    lista_link_comuni.append(link.get(\"href\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b5958",
   "metadata": {},
   "source": [
    "<b>Definisco la funzione per recuperare la stazione piu vicina</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9aabcdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\users\\nicho\\anaconda3\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from geopy) (2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cdc73236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance\n",
    " # long,lat of the house; df: metro_df or train_df\n",
    "def nearest_point(long, lat):\n",
    "    coords_1 = (long,lat)\n",
    "    distance=[]\n",
    "    for i in range(1, public_transport_df.shape[0]):\n",
    "        coords_2 = (public_transport_df.lon[i], public_transport_df.lat[i])\n",
    "        distance.append(geopy.distance.geodesic(coords_1, coords_2).km)\n",
    "    return({'index':distance.index(min(distance)) + 1, 'distance':round(min(distance),1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9293db7b",
   "metadata": {},
   "source": [
    "<b>Definisco la funzione per recuperare le zone o frazioni di un comune</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92a1983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupera_zone(soup, nome_comune_appartenenza, insertQueryComuni, insertQueryAffitti):\n",
    "    div_link_zone = soup.find_all('a', {\"class\": \"nd-table__url\"}, href=True)\n",
    "    lista_link_zone = []\n",
    "\n",
    "    for link in div_link_zone:\n",
    "        lista_link_zone.append(link.get(\"href\"))\n",
    "    \n",
    "    \n",
    "    for link in lista_link_zone:\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # recupero il nome del comune\n",
    "        nome = str(soup.find_all(\"li\", attrs = {\"class\": \"in-breadcrumbsLite__item nd-list__item\"})[4].get_text()).replace('\\t', '').replace('\\n', '')\n",
    "\n",
    "        # recupero le due strutture contenenti le vendite e affitti minimi e massimi, vendite e affitti medi\n",
    "        vendita_affitto_medio = soup.find_all(\"p\", attrs={\"class\": \"cg-buildingPricesStats__highlighted-text\"})\n",
    "\n",
    "        vendita_affitto = soup.find_all(\"p\", attrs={\"class\": \"cg-buildingPricesStats__highlighted-subtext\"})\n",
    "\n",
    "        # salvo le due stringhe contenenti vendite e affitti minimi e massimi   \n",
    "        stringa_vendite = str(vendita_affitto[0].get_text())\n",
    "        stringa_affitti = str(vendita_affitto[1].get_text())\n",
    "\n",
    "        # salvo nelle variabili\n",
    "\n",
    "        vendita_media = float(str(re.findall(r'\\d+[\\.,]?\\d+', str(vendita_affitto_medio[0].get_text()))[0]).replace('.', '').replace(',', '.'))\n",
    "        affitto_medio = float(str(re.findall(r'\\d+[\\.,]?\\d+', str(vendita_affitto_medio[1].get_text()))[0]).replace('.', '').replace(',', '.'))\n",
    "\n",
    "        if(stringa_vendite == '-'):\n",
    "            vendita_minima = 0\n",
    "            vendita_massima = 0\n",
    "        else:\n",
    "            vendita_minima = float(str(re.findall(r'\\d+[\\.,]?\\d+', stringa_vendite)[0]).replace('.', '').replace(',', '.'))\n",
    "            vendita_massima = float(str(re.findall(r'\\d+[\\.,]?\\d+', stringa_vendite)[1]).replace('.', '').replace(',', '.'))\n",
    "\n",
    "        if(stringa_affitti == '-'):\n",
    "            affitto_minimo = 0\n",
    "            affitto_massimo = 0\n",
    "        else:\n",
    "            affitto_minimo = float(str(re.findall(r'\\d+[\\.,]?\\d+', stringa_affitti)[0]).replace('.', '').replace(',', '.'))\n",
    "            affitto_massimo = float(str(re.findall(r'\\d+[\\.,]?\\d+', stringa_affitti)[1]).replace('.', '').replace(',', '.'))\n",
    "\n",
    "       \n",
    "        # recupero div con abitazioni, popolazione, eta media e reddito\n",
    "        superficie = 0\n",
    "        densita = 0\n",
    "        popolazione = 0\n",
    "        famiglie = 0\n",
    "        maschi = 0\n",
    "        femmine = 0\n",
    "        stranieri = 0\n",
    "        eta = 0\n",
    "    \n",
    "\n",
    "        # creo un nuovo record per la tabella comuni e lo inserisco\n",
    "        \n",
    "        # recupero il comuneId di appartenenza\n",
    "        cursor.execute(\"SELECT id FROM comuni WHERE nome = ?\", (nome_comune_appartenenza,))\n",
    "        comuneId_appartenenza = cursor.fetchone()[0]\n",
    "        \n",
    "         # faccio la insert\n",
    "\n",
    "        logging.info(\"Sto inserendo il \" + nome + \" del comune di \" + nome_comune_appartenenza + \" nella tabella COMUNI\")\n",
    "        cursor.execute(insertQueryComuni, \n",
    "                           (nome, nome_comune_appartenenza, comuneId_appartenenza, vendita_minima, vendita_media, vendita_massima, affitto_minimo, affitto_medio, affitto_massimo, popolazione, densita, superficie, famiglie, maschi, femmine, stranieri, eta))\n",
    "\n",
    "        conn.commit()\n",
    "        \n",
    "        # richiamo le funzioni per recuperare gli affitti\n",
    "        link_affitto = soup.find_all('a', {\"class\": \"cg-realEstateAdsCounters__link\"}, href=True)[1]\n",
    "        link_affitto = str(link_affitto['href'])\n",
    "        \n",
    "        # recupero id del comune o frazione\n",
    "        \n",
    "        cursor.execute(\"SELECT id FROM comuni WHERE nome = ? AND comuneId = ?\", (nome, comuneId_appartenenza))\n",
    "        comuneId = cursor.fetchone()[0]\n",
    "        \n",
    "        # richiamo le 2 funzioni\n",
    "        recupera_affitti(link_affitto, comuneId, insertQueryAffitti)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcfc757",
   "metadata": {},
   "source": [
    "<b>Definisco la funzione per recuperare gli affitti di un determinato comune</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7f89027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupera_affitti(link_affitto, comuneId, insertQueryAffitti):\n",
    "    \n",
    "    lista_link_affitti = recupera_all_annunci(link_affitto)\n",
    "    \n",
    "    logging.info(\"Sto inserendo gli annunci nella tabella AFFITTI, sono in totale: \" + str(len(lista_link_affitti)) + \"\\n\")\n",
    "    \n",
    "    for link in lista_link_affitti:\n",
    "        \n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # recupero il prezzo, luogo e tipologia di immobile\n",
    "        div_prezzo = soup.find(\"li\", class_=\"nd-list__item in-feat__item in-feat__item--main in-detail__mainFeaturesPrice\")\n",
    "        div_prezzo_altro = soup.find(\"li\", class_=\"nd-list__item in-feat__item in-feat__item--main in-detail__mainFeaturesPrice in-detail__mainFeaturesPrice--interactive\")\n",
    "        \n",
    "        if(div_prezzo is not None):\n",
    "            div_prezzo = str(div_prezzo.get_text()) \n",
    "            prezzo = re.findall(r'\\d+[\\.,]?\\d+', div_prezzo)\n",
    "            prezzo = float(str(prezzo[0]).replace('.', '').replace(',', '.')) if(len(prezzo) > 0) else 0\n",
    "        else:\n",
    "            div_prezzo = str(div_prezzo_altro.get_text()) if div_prezzo_altro is not None else '0'\n",
    "            prezzo = re.findall(r'\\d+[\\.,]?\\d+', div_prezzo)\n",
    "            prezzo = float(str(prezzo[0]).replace('.', '').replace(',', '.')) if (len(prezzo) > 0) else 0\n",
    "        \n",
    "        \n",
    "        # recupero il luogo e la tipologia di immobile\n",
    "        div_luogo = soup.find(\"h1\", class_=\"in-titleBlock__title\")            \n",
    "        indirizzo = ' '.join(str(div_luogo.get_text()).split()[1:]) if div_luogo is not None else '-'\n",
    "        #tipologia = str(str(div_luogo.get_text()).split()[0]) if div_luogo is not None else '-'\n",
    "        \n",
    "        \n",
    "        # recupero tutte le altre informazioni\n",
    "        \n",
    "        div_affitti = soup.find_all(\"dd\", class_=\"in-realEstateFeatures__value\")\n",
    "        if (len(div_affitti) > 4): \n",
    "            superficie = re.findall(r'\\d+[\\.,]?\\d+', str(div_affitti[3].get_text()))\n",
    "            superficie = float(str(superficie[0]).replace('.', '').replace(',', '.')) if (len(superficie) > 0) else 0\n",
    "            locali_descrizione = str(div_affitti[4].get_text())\n",
    "            locali = re.findall(r'\\d', locali_descrizione)\n",
    "            locali = int(locali[0]) if (len(locali) > 0) else 0\n",
    "            piani = str(div_affitti[5].get_text())\n",
    "        else:\n",
    "            locali_descrizione = ''\n",
    "            superficie = 0\n",
    "            locali = 0\n",
    "            piani = ''\n",
    "            \n",
    "        # recupero tramite lo script le informazioni necessarie\n",
    "        item_annuncio = soup.find(\"script\", id=\"__NEXT_DATA__\")\n",
    "        \n",
    "        if (item_annuncio is not None and len(item_annuncio) > 0):\n",
    "\n",
    "            item_annuncio = str(item_annuncio).replace('<script id=\"__NEXT_DATA__\" type=\"application/json\">', '').replace('</script>', '')\n",
    "            json_dict = json.loads(item_annuncio)\n",
    "\n",
    "            nome = json_dict['props']['pageProps']['detailData']['realEstate']['title']\n",
    "            contratto = json_dict['props']['pageProps']['detailData']['realEstate']['contractValue']\n",
    "            latitudine = json_dict['props']['pageProps']['detailData']['realEstate']['properties'][0]['location']['latitude']\n",
    "            longitudine = json_dict['props']['pageProps']['detailData']['realEstate']['properties'][0]['location']['longitude']\n",
    "            tipologia = json_dict['props']['pageProps']['detailData']['realEstate']['properties'][0]['typologyValue']\n",
    "            prezzo_minimo = json_dict['props']['pageProps']['detailData']['trovakasa']['minPrice']\n",
    "            prezzo_minimo = float(prezzo_minimo) if prezzo_minimo is not None else 0\n",
    "            prezzo_massimo = json_dict['props']['pageProps']['detailData']['trovakasa']['maxPrice']\n",
    "            prezzo_massimo = float(prezzo_massimo) if prezzo_massimo is not None else 0\n",
    "            box_auto = json_dict['props']['pageProps']['detailData']['trovakasa']['boxAutoId']\n",
    "            box_auto = 0 if box_auto is None else int(box_auto)\n",
    "            giardino = json_dict['props']['pageProps']['detailData']['trovakasa']['garden']\n",
    "            giardino = 0 if giardino is None else int(giardino)\n",
    "            balcone = json_dict['props']['pageProps']['detailData']['trovakasa']['balcony']\n",
    "            balcone = 0 if balcone is None else 1\n",
    "            ascensore = json_dict['props']['pageProps']['detailData']['trovakasa']['elevator']\n",
    "            ascensore = 0 if ascensore is None else int(ascensore)\n",
    "            fumatori = json_dict['props']['pageProps']['detailData']['trovakasa']['smoker']\n",
    "            fumatori = 0 if fumatori is None else int(fumatori)\n",
    "            animali = json_dict['props']['pageProps']['detailData']['trovakasa']['animals']\n",
    "            animali = 0 if animali is None else int(animali)\n",
    "        else:\n",
    "            nome = ''\n",
    "            contratto = ''\n",
    "            latitudine = ''\n",
    "            longitudine = ''\n",
    "            tipologia = ''\n",
    "            prezzo_minimo = 0\n",
    "            prezzo_massimo = 0\n",
    "            box_auto = 0 \n",
    "            giardino = 0\n",
    "            balcone = 0 \n",
    "            ascensore = 0 \n",
    "            fumatori = 0\n",
    "            animali = 0\n",
    "\n",
    "        # stazione piu vicina implementando le API\n",
    "        dizionario = nearest_point(longitudine, latitudine)\n",
    "        stazioneId = int(dizionario['index'])\n",
    "        stazione_distanza = int(dizionario['distance'] * 1000)\n",
    "        stazione_tempo = int(dizionario['distance'] * 12)\n",
    "        \n",
    "        # controllo che non sia gia salvato l'annuncio \n",
    "        cursor.execute(\"SELECT id FROM affitti WHERE url_annuncio = ?\", (link,))\n",
    "        nonEsiste = True if cursor.fetchone() is None else False\n",
    "        \n",
    "        if(nonEsiste):\n",
    "            # inserisco un nuovo record nella tabella affitti\n",
    "            cursor.execute(insertQueryAffitti, (nome, comuneId, contratto, tipologia, superficie, locali, locali_descrizione, piani, indirizzo, latitudine, longitudine, stazioneId, stazione_distanza, stazione_tempo, prezzo, prezzo_minimo, prezzo_massimo, box_auto, giardino, balcone, ascensore, fumatori, animali, link))\n",
    "            conn.commit()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7435361",
   "metadata": {},
   "source": [
    "<b>Definisco la funzione per recuperare tutti gli annunci di affitto di un comune o frazione</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3c42bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupera_all_annunci(link_pagina):\n",
    "    \n",
    "    #print(\"Sto recuperando gli annunci...\")\n",
    "    logging.info(\"Sto recuperando gli annunci...\")\n",
    "    lista_link_annunci = []\n",
    "    numero_pagina = 1\n",
    "    annunci = []\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        response = requests.get(link_pagina + \"?pag=\" + str(numero_pagina))\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        pagina_non_esiste = soup.find(\"div\", class_=\"nd-alert nd-alert--warning in-errorMessage__alert in-errorMessage__title\")\n",
    "\n",
    "        if (pagina_non_esiste is None):\n",
    "\n",
    "            div_link_annunci = soup.find_all(\"div\", class_=\"in-card nd-mediaObject nd-mediaObject--colToRow in-realEstateCard in-realEstateCard--interactive in-realEstateListCard\")\n",
    "            \n",
    "            for link in div_link_annunci:\n",
    "                link_annuncio = link.find(\"a\", class_=\"in-card__title\")\n",
    "                if len(link_annuncio) > 0:\n",
    "                    lista_link_annunci.append(link_annuncio[\"href\"])     \n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "        numero_pagina = numero_pagina + 1\n",
    "            \n",
    "    return lista_link_annunci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aa81d3",
   "metadata": {},
   "source": [
    "<b>Definisco una funzione per visualizzare il tempo necessario allo scraping:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52e3a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stampaTempi(ora_inzio, ora_fine):\n",
    "    differenza = ora_fine - ora_inizio\n",
    "    ore = differenza.seconds // 3600\n",
    "    minuti = (differenza.seconds // 60) % 60\n",
    "    secondi = differenza.seconds % 60\n",
    "    return \"Il tempo totale di esecuzione e' di \" + str(ore) + \" ore, \" + str(minuti) + \" minuti e \" + str(secondi) + \" secondi\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95b0ded",
   "metadata": {},
   "source": [
    "<b>Configuro il file di log con le informazioni</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff185718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione del logger\n",
    "logging.basicConfig(filename='file_di_log.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9b0c7",
   "metadata": {},
   "source": [
    "<b>Devo recuperare una lista con le informazioni dei comuni dal sito ugeo.urbistat.com</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f85312c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://ugeo.urbistat.com/adminstat/it/it/demografia/dati-sintesi/milano/15/3\")\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "div_link_comuni = soup.find_all(\"ul\", class_=\"box_list box_list_l_3s\")\n",
    "\n",
    "link_comuni1 = div_link_comuni[0].find_all(\"a\")\n",
    "\n",
    "link_comuni2 = div_link_comuni[1].find_all(\"a\")\n",
    "\n",
    "link_comuni3 = div_link_comuni[2].find_all(\"a\")\n",
    "\n",
    "elenco_link_comuni = []\n",
    "\n",
    "for link in link_comuni1:\n",
    "    elenco_link_comuni.append(link['href'])\n",
    "\n",
    "for link in link_comuni2:\n",
    "    elenco_link_comuni.append(link['href'])\n",
    "\n",
    "for link in link_comuni3:\n",
    "    elenco_link_comuni.append(link['href'])\n",
    "    \n",
    "elenco_link_comuni.insert(0, elenco_link_comuni.pop(72))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fc2387",
   "metadata": {},
   "source": [
    "<b>Inizio a prelevare le informazioni sui comuni e i relativi affitti:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7b2f0069",
   "metadata": {},
   "outputs": [],
   "source": [
    "ora_inizio = dt.now()\n",
    "ora_inizio_formatted = ora_inizio.strftime(\"%H:%M:%S\")\n",
    "open('file_di_log.log', 'w').close()\n",
    "logging.info(\"L'esecuzione e' iniziata alle: \" + ora_inizio_formatted + \"\\n\\n\")\n",
    "numero = 0\n",
    "for link in lista_link_comuni:\n",
    "    \n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # recupero il nome del comune\n",
    "    nome = str(soup.find_all(\"li\", attrs = {\"class\": \"in-breadcrumbsLite__item nd-list__item\"})[3].get_text()).replace('\\t', '').replace('\\n', '')\n",
    "    \n",
    "    # recupero le due strutture contenenti le vendite e affitti minimi e massimi, vendite e affitti medi\n",
    "    vendita_affitto_medio = soup.find_all(\"p\", attrs={\"class\": \"cg-buildingPricesStats__highlighted-text\"})\n",
    "    vendita_affitto = soup.find_all(\"p\", attrs={\"class\": \"cg-buildingPricesStats__highlighted-subtext\"})\n",
    "    \n",
    "    # salvo le due stringhe contenenti vendite e affitti minimi e massimi   \n",
    "    stringa_vendite = str(vendita_affitto[0].get_text())\n",
    "    stringa_affitti = str(vendita_affitto[1].get_text())\n",
    "    \n",
    "    # salvo nelle variabili\n",
    "    \n",
    "    vendita_media = float(str(re.findall(r'\\d+[\\.,]?\\d+', str(vendita_affitto_medio[0].get_text()))[0]).replace('.', '').replace(',', '.'))\n",
    "    affitto_medio = float(str(re.findall(r'\\d+[\\.,]?\\d+', str(vendita_affitto_medio[1].get_text()))[0]).replace('.', '').replace(',', '.'))\n",
    "    \n",
    "    if(stringa_vendite == '-'):\n",
    "        vendita_minima = 0\n",
    "        vendita_massima = 0\n",
    "    else:\n",
    "        vendita_minima = float(re.findall(r'\\d+[\\.,]?\\d+', stringa_vendite.replace('.', '').replace(',', '.'))[0])\n",
    "        vendita_massima = float(re.findall(r'\\d+[\\.,]?\\d+', stringa_vendite.replace('.', '').replace(',', '.'))[1])\n",
    "    \n",
    "    if(stringa_affitti == '-'):\n",
    "        affitto_minimo = 0\n",
    "        affitto_massimo = 0\n",
    "    else:\n",
    "        affitto_minimo = float(re.findall(r'\\d+[\\.,]?\\d+', stringa_affitti.replace('.', '').replace(',', '.'))[0])\n",
    "        affitto_massimo = float(re.findall(r'\\d+[\\.,]?\\d+', stringa_affitti.replace('.', '').replace(',', '.'))[1])\n",
    "    \n",
    "    \n",
    "    # recupero tutte le informazioni superficie, abitanti, densita e cap\n",
    "    \n",
    "    response = requests.get(\"https://ugeo.urbistat.com\"+str(elenco_link_comuni[numero]))\n",
    "    soup_other = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    div = soup_other.find(\"div\", class_=\"table_data row\")\n",
    "    div_tr = div.find_all(\"tr\")\n",
    "    superficie = float(str(div_tr[4].find_all(\"td\")[1].find(\"span\").get_text()).replace('.','').replace(',','.'))\n",
    "    densita = float(str(div_tr[5].find_all(\"td\")[1].find(\"span\").get_text()).replace('.','').replace(',','.'))\n",
    "    popolazione = float(str(div_tr[6].find_all(\"td\")[1].find(\"span\").get_text()).replace('.','').replace(',','.'))\n",
    "    famiglie = float(str(div_tr[7].find_all(\"td\")[1].find(\"span\").get_text()).replace('.','').replace(',','.'))\n",
    "    maschi = float(str(div_tr[8].find_all(\"td\")[1].find(\"span\").get_text()).replace('.','').replace(',','.'))\n",
    "    femmine = float(str(div_tr[9].find_all(\"td\")[1].find(\"span\").get_text()).replace('.','').replace(',','.'))\n",
    "    stranieri = float(str(div_tr[10].find_all(\"td\")[1].find(\"span\").get_text()).replace('.','').replace(',','.'))\n",
    "    eta = float(str(div_tr[11].find_all(\"td\")[1].find(\"span\").get_text()).replace('.','').replace(',','.'))\n",
    "    #elenco_righe_table = div.find_all(\"tr\")\n",
    "    \n",
    "    #popolazione = float(re.findall(r'(\\d{1,3}(?:\\.\\d{3})*(?:,\\d+)?)\\s+abitanti',str(elenco_righe_table[3].find_all(\"td\")[1].get_text()))[0].replace('.', '').replace(',', '.'))\n",
    "    #superficie = float(re.findall(r'(\\d{1,3}(?:\\.\\d{3})*(?:,\\d+)?)\\s+km²',str(elenco_righe_table[4].find_all(\"td\")[1].get_text()))[0].replace('.', '').replace(',', '.'))\n",
    "    #densita = float(re.findall(r'(\\d{1,3}(?:\\.\\d{3})*(?:,\\d+)?)\\s+ab./km²',str(elenco_righe_table[5].find_all(\"td\")[1].get_text()))[0].replace('.', '').replace(',', '.'))\n",
    "    \n",
    "    #popolazione = 0\n",
    "    #superficie = 0\n",
    "    #densita = 0\n",
    "    #cap = int(str(elenco_righe_table[10].find_all(\"td\")[1].find(\"span\").get_text()))\n",
    "    #cap = 0\n",
    "    \n",
    "    # creo un nuovo record per la tabella comuni e lo inserisco\n",
    "    \n",
    "    # recupero l'id massimo della tabella comuni\n",
    "    cursor.execute(\"SELECT max(id) FROM comuni\")\n",
    "    \n",
    "    risultato = cursor.fetchone()\n",
    "    valore_max_id = risultato[0] if risultato[0] is not None else 0\n",
    "    \n",
    "    comuneId = valore_max_id +1\n",
    "    \n",
    "    # richiamo la funzione per recuperare le zone o frazioni di un comune se esistono\n",
    "    haZone = soup.find(\"th\", attrs={\"class\": \"nd-table__heading\"}).get_text() == 'Zone'\n",
    "\n",
    "    # creo la query di insert nel db per tabella comuni\n",
    "    insertQueryComuni = \"INSERT INTO comuni \"\n",
    "    insertQueryComuni += \"(nome, comune_appartenenza, comuneId, `vendita_minima(€/mese)`, `vendita_media(€/mese)`, `vendita_massima(€/mese)`, `affitto_minimo(€/mese)`, `affitto_medio(€/mese)`, `affitto_massimo(€/mese)`, popolazione, `densita_popolazione(ab./km²)`, `superficie(km²)`, famiglie, `maschi(%)`, `femmine(%)`, `stranieri(%)`, `eta_media(anni)`)\"\n",
    "    insertQueryComuni += \"VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\n",
    "              \n",
    "    # stampo 2 diverse strighe nel log\n",
    "    if (haZone):\n",
    "        logging.info(str(numero+1) + \") Sto inserendo il comune di \" + nome + \" nella tabella COMUNI\\n\")\n",
    "    else:\n",
    "        logging.info(str(numero+1) + \") Sto inserendo il comune di \" + nome + \" nella tabella COMUNI\")\n",
    "     \n",
    "    numero = numero + 1\n",
    "    \n",
    "\n",
    "    # faccio la insert\n",
    "    cursor.execute(insertQueryComuni, \n",
    "                   (nome, nome, comuneId, vendita_minima, vendita_media, vendita_massima, affitto_minimo, affitto_medio, affitto_massimo, popolazione, densita, superficie, famiglie, maschi, femmine, stranieri, eta))\n",
    "\n",
    "    conn.commit()\n",
    "    \n",
    "    # recupero i link degli affitti e le vendite\n",
    "    link_vendite = soup.find_all('a', {\"class\": \"cg-realEstateAdsCounters__link\"}, href=True)[0]\n",
    "    link_vendite = str(link_vendite['href'])\n",
    "    link_affitto = soup.find_all('a', {\"class\": \"cg-realEstateAdsCounters__link\"}, href=True)[1]\n",
    "    link_affitto = str(link_affitto['href'])\n",
    "\n",
    "    \n",
    "    # scrivo la query per affitti\n",
    "    insertQueryAffitti = \"INSERT INTO affitti \"\n",
    "    insertQueryAffitti += \"(nome, comuneId, contratto, tipologia, `superficie(m²)`, locali, locali_descrizione, piani, indirizzo, latitudine, longitudine, stazioneId, `stazione_distanza(metri)`, `stazione_distanza(minuti)`, `prezzo(€/mese)`, `prezzo_minimo(€/mese)`, `prezzo_massimo(€/mese)`, box_auto, `giardino(m²)`, balcone, ascensore, fumatori, animali, url_annuncio)\"\n",
    "    insertQueryAffitti += \"VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\n",
    "    \n",
    "    \n",
    "    if (haZone):\n",
    "        # se ha delle zone o frazioni recupero gli affitti solamente delle zone\n",
    "        recupera_zone(soup, nome, insertQueryComuni, insertQueryAffitti)\n",
    "    else:\n",
    "        # se non le ha recupero le zone solo del comune\n",
    "        recupera_affitti(link_affitto, comuneId, insertQueryAffitti)\n",
    "    \n",
    "      \n",
    "conn.close()\n",
    "ora_fine = dt.now()\n",
    "ora_fine_formatted = ora_fine.strftime(\"%H:%M:%S\")\n",
    "logging.info(\"L'esecuzione e' terminata alle: \" + ora_fine_formatted)\n",
    "logging.info(stampaTempi(ora_inizio, ora_fine))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
